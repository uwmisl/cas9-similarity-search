{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run Analyses\n",
    "\n",
    "Given run data, outputs PDF analysis summaries and, for each run, a directory of png outputs. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import primo.analysis.run_analysis_functions\n",
    "import os\n",
    "import gzip\n",
    "import shutil\n",
    "import csv\n",
    "# from fpdf import FPDF\n",
    "import pandas as pd\n",
    "from tqdm import tqdm # for progress bar\n",
    "import matplotlib.pyplot as plt\n",
    "from Bio.SeqIO import parse\n",
    "from Bio.Seq import Seq\n",
    "from Bio import pairwise2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "SCORE_THRESH = 17 # my rule of thumb, this value is\n",
    "                # len(alignment_seq) - 3\n",
    "                # for queries >= 20nt but less for shorter queries.\n",
    "                # Note that the score threshold will only return sequences\n",
    "                # with alignment score > threshold so if your query is 20nt\n",
    "                # your maximum alignment score will be 20\n",
    "\n",
    "MAX_READ_LEN = 500 # often the sequence aligner chokes on long sequences, this is the maximum\n",
    "                    # length a sequence is allowed to be in order to be analyzed, longer reads\n",
    "                    # are totally ignored"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set the baseline\n",
    "This analyzes run data for the baseline pool. You may skip this section if you have already run it before."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEQS_TO_ALIGN = sys.argv[1]\n",
    "INITIAL_POOL_DIR_PATH = sys.argv[2]\n",
    "date_label = INITIAL_POOL_DIR_PATH.split('/')[-1].split('_')[0]\n",
    "CURRENT_DIR = os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unzip all fastq files from FASTQ_PASS dir\n",
    "print('Unzipping Fastq files')\n",
    "gz_extract(INITIAL_POOL_DIR_PATH)\n",
    "\n",
    "# Read in all target seqs (seqs to align reads to) as dictionary\n",
    "print('Reading in target sequences')\n",
    "target_dict = csv_to_dict(SEQS_TO_ALIGN)\n",
    "\n",
    "# Read in FASTQ_PASS nanopore data and see which reads align to any of the seqs to align to\n",
    "# NOTE- any read aligning to more than seq will be discarded\n",
    "print('Aligning reads to target sequences')\n",
    "aligned_reads = align_reads(target_dict, INITIAL_POOL_DIR_PATH)\n",
    "aligned_reads_text = f'Number of aligned reads (with duplicate reads):{len(aligned_reads)}'\n",
    "\n",
    "# Remove all reads that aligned to multiple sequences\n",
    "print('Removing all reads with multiple alignments')\n",
    "aligned_reads = remove_duplicate_reads(aligned_reads)\n",
    "cleaned_aligned_reads_text = f'Number of aligned reads (no duplicate reads):{len(aligned_reads)}'\n",
    "\n",
    "# Write dataframe to csv\n",
    "print('Writing aligned read data to csv')\n",
    "csv_name = f'{create_data_dir(CURRENT_DIR, date_label)}/baseline_pool_data.csv'\n",
    "aligned_reads.to_csv(csv_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Data is being analyzed')\n",
    "# Plot number of reads each sequence got\n",
    "barfig_name = plot_target_freq(aligned_reads, CURRENT_DIR, date_label)\n",
    "\n",
    "# Get a list of all the read lengths in the directory\n",
    "all_read_lengths_in_dir = get_read_lens(INITIAL_POOL_DIR_PATH)\n",
    "\n",
    "# Get a descriptive string of the total number of reads in the directory\n",
    "total_reads_str = get_total_dir_reads(all_read_lengths_in_dir)\n",
    "\n",
    "# Plot read length distribution for reads in FASTQ_PASS dir\n",
    "len_dist_name = plot_len_distribution(all_read_lengths_in_dir, CURRENT_DIR, date_label)\n",
    "# Plot read length distribution of reads length 0 to max_read_len\n",
    "len_dist_zoomed_name = plot_len_distribution_zoomed(all_read_lengths_in_dir, CURRENT_DIR, date_label)\n",
    "\n",
    "# Make PDF and write data to it\n",
    "print('Making PDF (this is a slow process, give it a minute or two)')\n",
    "pdf = initialize_pdf_expt0(date_label)\n",
    "text = total_reads_str + '\\n' + aligned_reads_text + '\\n' + cleaned_aligned_reads_text\n",
    "pdf.multi_cell(200,30, txt=text, align='L')\n",
    "\n",
    "default_image_width = 150\n",
    "default_image_height = 110\n",
    "pdf.image(barfig_name, w=default_image_width, h=default_image_height)\n",
    "pdf.image(len_dist_name, w=default_image_width, h=default_image_height)\n",
    "pdf.image(len_dist_zoomed_name, w=default_image_width, h=default_image_height)\n",
    "\n",
    "pdf.output(f'{create_data_dir(CURRENT_DIR, date_label)}/{date_label}_css_analysis_summary.pdf')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyze Similarity Search Run Data\n",
    "This analyzes run data where an alequot of the baseline pool has been queried with Cas9. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEQS_TO_ALIGN = sys.argv[1]\n",
    "INITIAL_POOL_INFO = sys.argv[2]\n",
    "EXPERIMENT_DIR = sys.argv[3]\n",
    "date_label = EXPERIMENT_DIR.split('/')[-1].split('_')[0]\n",
    "CURRENT_DIR = os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in baseline pool information\n",
    "unmodified_df = pd.read_csv(INITIAL_POOL_INFO)\n",
    "\n",
    "# Unzip all fastq files from FASTQ_PASS dir\n",
    "print('Unzipping Fastq files')\n",
    "gz_extract(EXPERIMENT_DIR)\n",
    "\n",
    "# Read in all target seqs (seqs to align reads to) as dictionary\n",
    "print('Reading in target sequences')\n",
    "target_dict = csv_to_dict(SEQS_TO_ALIGN)\n",
    "\n",
    "# Read in FASTQ_PASS nanopore data and see which reads align to any of the seqs to align to\n",
    "# NOTE- any read aligning to more than seq will eventually be discarded\n",
    "print('Aligning reads to target sequences')\n",
    "aligned_reads = align_reads(target_dict, EXPERIMENT_DIR)\n",
    "aligned_reads_text = f'Number of aligned reads (with duplicate alignments):{len(aligned_reads)}'\n",
    "\n",
    "# Remove all reads that aligned to multiple sequences\n",
    "print('Removing all reads with multiple alignments')\n",
    "aligned_reads = remove_duplicate_reads(aligned_reads)\n",
    "cleaned_aligned_reads_text = f'Number of aligned reads (no duplicate alignments):{len(aligned_reads)}'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Data is being analyzed')\n",
    "# Plot raw number of reads each sequence got\n",
    "barfig_name = plot_target_freq(aligned_reads, CURRENT_DIR, date_label)\n",
    "\n",
    "# Get a list of all the read lengths in the directory\n",
    "all_read_lengths_in_dir = get_read_lens(EXPERIMENT_DIR)\n",
    "\n",
    "# Get a descriptive string of the total number of reads in the directory\n",
    "total_reads_str = get_total_dir_reads(all_read_lengths_in_dir)\n",
    "\n",
    "# Plot read length distribution for reads in FASTQ_PASS dir\n",
    "len_dist_name = plot_len_distribution(all_read_lengths_in_dir, CURRENT_DIR, date_label)\n",
    "\n",
    "# Plot read length distribution of reads length 0 to max_read_len\n",
    "len_dist_zoomed_name = plot_len_distribution_zoomed(all_read_lengths_in_dir, CURRENT_DIR, date_label)\n",
    "\n",
    "# Calculate enrichment score and plot those results\n",
    "initial_ratios = calculate_enrichment_scores(unmodified_df)\n",
    "expt_ratios = calculate_enrichment_scores(aligned_reads)\n",
    "enrichment_score_barfig_name = plot_es_barplot(expt_ratios, initial_ratios, CURRENT_DIR, date_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make PDF and write data to it\n",
    "print('Making PDF (this is a slow process, give it a minute or two)')\n",
    "pdf = initialize_pdf(date_label)\n",
    "text = total_reads_str + '\\n' + aligned_reads_text + '\\n' + cleaned_aligned_reads_text\n",
    "pdf.multi_cell(200,30, txt=text, align='L')\n",
    "\n",
    "default_image_width = 150\n",
    "default_image_height = 110\n",
    "pdf.image(barfig_name, w=default_image_width, h=default_image_height)\n",
    "pdf.image(enrichment_score_barfig_name, w=default_image_width, h=default_image_height)\n",
    "pdf.image(len_dist_name, w=default_image_width, h=default_image_height)\n",
    "pdf.image(len_dist_zoomed_name, w=default_image_width, h=default_image_height)\n",
    "\n",
    "pdf.output(f'{create_data_dir(CURRENT_DIR, date_label)}/{date_label}_css_analysis_summary.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
