{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run Simulations\n",
    "\n",
    "Given an encoded dataset of targets and queries, run simulations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Consider modifying this to simualate the nucleaseq output score https://github.com/uwmisl/cas9-similarity-search/issues/3\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import primo.models\n",
    "\n",
    "#import cupyck\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "QUERY = 'callie_janelle'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hosts = [\n",
    "#     (\"localhost\", 2046),\n",
    "# ]\n",
    "# client = cupyck.Client(hosts)\n",
    "# simulator = primo.models.Simulator(client)\n",
    "simulator = primo.models.Simulator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#target_seqs = pd.read_hdf('/tf/primo/data/extended_targets/feature_seqs.h5')\n",
    "target_seqs = pd.read_hdf('/tf/primo/data/targets/feature_seqs.h5')\n",
    "query_seqs = pd.read_hdf('/tf/primo/data/queries/feature_seqs.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "139056 / 1743042 (8.0%)\n"
     ]
    }
   ],
   "source": [
    "n_unique = len(target_seqs['FeatureSequence'].unique())\n",
    "n_total = len(target_seqs['FeatureSequence'])\n",
    "print(f\"{n_unique} / {n_total} ({float(n_unique) * 100 / n_total:0.1f}%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "pairs = (target_seqs\n",
    " .rename(columns={'FeatureSequence':'target_features'})\n",
    " .assign(query_features = query_seqs.loc[QUERY].FeatureSequence)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4,000 here is just a memory-management batch size so that each progress chunk reports period of time.\n",
    "split_size = 4_000\n",
    "nsplits = len(pairs) / split_size\n",
    "splits = np.array_split(pairs, nsplits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "308c7e19e64d4b489655eb6d83f384bb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/435 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "result_store = pd.HDFStore(f'/tf/primo/data/simulation/extended_targets/{QUERY}.h5', complevel=9, mode='w')\n",
    "try:\n",
    "    for split in tqdm(splits):\n",
    "        results = simulator.simulate(split)\n",
    "        result_store.append('df', pd.DataFrame({'duplex_yield': results}, index=split.index))\n",
    "finally:\n",
    "    result_store.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
