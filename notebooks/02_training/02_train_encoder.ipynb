{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Encoder Training\n",
    "=============="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Matplotlib created a temporary config/cache directory at /tmp/matplotlib-1kdc0kbz because the default path (/tf/.cache/matplotlib) is not a writable directory; it is highly recommended to set the MPLCONFIGDIR environment variable to a writable directory, in particular to speed up the import of Matplotlib and to better support multiprocessing.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "%pylab notebook\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "import primo.models\n",
    "import primo.datasets\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reserve space on the GPU for running simulations. It's important to do this before running any tensorflow code (which will take all available GPU memory):"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load up the training and validation datasets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = primo.datasets.OpenImagesTrain(\n",
    "    '/tf/open_images/train/', switch_every=10**5\n",
    ")\n",
    "\n",
    "validation_dataset = primo.datasets.OpenImagesVal('/tf/open_images/validation/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def keras_batch_generator(dataset_batch_generator, similarity_threshold):\n",
    "    # Yield datasets\n",
    "    # TODO: Verify with Callie this understanding is correct https://github.com/uwmisl/cas9-similarity-search/issues/2\n",
    "    while True:\n",
    "        # This tuple contains:\n",
    "        # indices: a positive integer uniquely identifying an image. This index is obtained by enumerating all the images in the dataset (before splitting them into test/train/validate datasets)\n",
    "        # pairs:\n",
    "        indices, pairs = next(dataset_batch_generator)\n",
    "        # The Euclidean distances between the two vectors in each pair\n",
    "        distances = np.sqrt(np.square(pairs[:,0,:] - pairs[:,1,:]).sum(1))\n",
    "        # Whether or not the images in this pair should be considered 'similar'. This is a boolean value, represented by an int (0 or 1), and is determined by whether the aforementioned Euclidean distances between image feature vectors are under some pre-deterined \"similarity threshold\".\n",
    "        similar = (distances < similarity_threshold).astype(int)\n",
    "        # Yield a pair of sequences, and 0-or-1 indicating whether they're similar.\n",
    "        yield pairs, similar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To see how this value was derived, please consult the Materials and Methods subsection under Feature Extraction section.\n",
    "similarity_threshold = 75\n",
    "# Intuitively determined:\n",
    "encoder_training_dataset_batch_size = 100\n",
    "# Intuitively determined:\n",
    "encoder_validation_dataset_batch_size = 2500\n",
    "\n",
    "encoder_train_batches = keras_batch_generator(\n",
    "    train_dataset.balanced_pairs(encoder_training_dataset_batch_size, similarity_threshold),\n",
    "    similarity_threshold\n",
    ")\n",
    "\n",
    "encoder_val_batches = keras_batch_generator(\n",
    "    validation_dataset.random_pairs(encoder_validation_dataset_batch_size),\n",
    "    similarity_threshold\n",
    ")\n",
    "\n",
    "# TODO: The new predictor is the nucleaseq Cas9 predictor. https://github.com/uwmisl/cas9-similarity-search/issues/3\n",
    "predictor_train_batch_size = 1000\n",
    "predictor_train_batches = train_dataset.random_pairs(predictor_train_batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create the models and stack them together with the trainer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/bin/sh: 1: Syntax error: word unexpected (expecting \")\")\r\n"
     ]
    }
   ],
   "source": [
    "# Yield predictor here is a differentiable DNA hybridization yield predictor (originally learned from the Nupack simulator). Represented in brown to the right of the one-hot box.\n",
    "![big](../../documentation/similarity_search_schematic.jpg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = primo.models.Encoder()\n",
    "\n",
    "# TODO: Replace the yield_predictor with the nucleaseq Cas9 predictor, use that here instead. https://github.com/uwmisl/cas9-similarity-search/issues/3 \n",
    "#yield_predictor = primo.models.Predictor('/tf/primo/data/models/yield-model.h5')\n",
    "yield_predictor = primo.models.PredictorFunction()\n",
    "encoder.model.compile()\n",
    "yield_predictor.model.compile()\n",
    "encoder_trainer = primo.models.EncoderTrainer(encoder, yield_predictor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the training!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_trainer.model.compile(tf.keras.optimizers.Adagrad(1e-3), 'binary_crossentropy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py:1940: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  warnings.warn('`Model.fit_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "switching to train_7.h5 and train_a.h5\n",
      "Epoch 1/10\n",
      "500/500 - 21s - loss: 1.7592 - val_loss: 0.0861\n",
      "Epoch 2/10\n",
      "500/500 - 20s - loss: 1.6681 - val_loss: 0.0832\n",
      "Epoch 3/10\n",
      "500/500 - 20s - loss: 1.6605 - val_loss: 0.0765\n",
      "Epoch 4/10\n",
      "500/500 - 20s - loss: 1.6576 - val_loss: 0.0814\n",
      "Epoch 5/10\n",
      "500/500 - 20s - loss: 1.6559 - val_loss: 0.0842\n",
      "Epoch 6/10\n",
      "500/500 - 20s - loss: 1.6546 - val_loss: 0.0928\n",
      "Epoch 7/10\n",
      "500/500 - 20s - loss: 1.6552 - val_loss: 0.0855\n",
      "Epoch 8/10\n",
      "500/500 - 20s - loss: 1.6512 - val_loss: 0.0726\n",
      "Epoch 9/10\n",
      "500/500 - 20s - loss: 1.6503 - val_loss: 0.0817\n",
      "Epoch 10/10\n",
      "500/500 - 20s - loss: 1.6510 - val_loss: 0.0867\n"
     ]
    }
   ],
   "source": [
    "history = encoder_trainer.model.fit_generator(\n",
    "    encoder_train_batches,\n",
    "#     steps_per_epoch = 1000,\n",
    "#     epochs = 100,\n",
    "    steps_per_epoch = 500,\n",
    "    epochs = 10,\n",
    "    validation_data = encoder_val_batches,\n",
    "    validation_steps = 1,\n",
    "    verbose = 2\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save the models:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder.save('/tf/primo/data/models/encoder-model-short.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 2, 4096)]    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lambda_2 (Lambda)               ((None, 4096), (None 0           input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "encoder (Sequential)            (None, 20, 4)        8554576     lambda_2[0][0]                   \n",
      "                                                                 lambda_2[0][1]                   \n",
      "__________________________________________________________________________________________________\n",
      "lambda_4 (Lambda)               (None, 20, 4, 2)     0           encoder[0][0]                    \n",
      "                                                                 encoder[1][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lambda_5 (Lambda)               (None, 2, 20, 4)     0           lambda_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "sequential (Sequential)         (None,)              0           lambda_5[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 8,554,576\n",
      "Trainable params: 8,554,576\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "encoder_trainer.model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query Seqs: ['TAAAAAAAAAAAAGAAAAAA' 'TAAAAAAAAAAAAGAAAAAA' 'GAAAAAAAAAAAAGAAAAAA']\n"
     ]
    }
   ],
   "source": [
    "import primo.tools.filepath as filepaths\n",
    "import primo.tools.sequences as seqtools\n",
    "import pandas as pd\n",
    "query_features_filepath = filepaths.get_query_features_path(isDocker=True)\n",
    "query_features = pd.read_hdf(query_features_filepath)\n",
    "query_seqs = encoder.encode_feature_seqs(query_features)\n",
    "print(f\"Query Seqs: {query_seqs}\")\n",
    "\n",
    "def seq_str_to_input(seq):\n",
    "    return np.transpose(seqtools.seqs_to_onehots(seq), [1, 0, 2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Full model: [0.0324022]\n",
      "Predictor with sequences: [1.]\n"
     ]
    }
   ],
   "source": [
    "a = encoder_trainer.model.predict(np.array([[query_features.loc['callie_janelle'], query_features.loc['callie_janelle']]]))\n",
    "print(f\"Full model: {a}\")\n",
    "\n",
    "b = encoder_trainer.predictor.model.predict(np.array([\n",
    "    np.concatenate([\n",
    "        seq_str_to_input('TAAAAAAAAAAAAGAAAAAA'),\n",
    "        seq_str_to_input('TAAAAAAAAAAAAGAAAAAA'),\n",
    "    ]),\n",
    "]))\n",
    "print(f\"Predictor with sequences: {b}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([101.17676], dtype=float32)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder_trainer.calcdists.predict(np.array([[query_features.loc['callie_janelle'], query_features.loc['luis_lego']]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = next(encoder_train_batches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 2, 20, 4)\n",
      "[0.03016231]\n",
      "[96.10688]\n"
     ]
    }
   ],
   "source": [
    "pair = batch[0][12]\n",
    "seqs = np.array([encoder.model.predict(pair)])\n",
    "print(seqs.shape)\n",
    "print(encoder_trainer.predictor.model.predict(seqs))\n",
    "print(encoder_trainer.calcdists.predict(np.array([pair])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2,), dtype=float32, numpy=array([1.000000e+00, 1.999998e-04], dtype=float32)>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "encoder_trainer.predictor.model(np.array([\n",
    "    np.concatenate([\n",
    "        seq_str_to_input('TAAAAAAAAAAAAGAAAAAA'),\n",
    "        seq_str_to_input('TAAAAAAAAAAAAGAAAAAA'),\n",
    "    ]),\n",
    "    np.concatenate([\n",
    "        seq_str_to_input('GACATCAACGAACAAAGTAA'),\n",
    "        seq_str_to_input('GAAAACAAAAAAAAAAAAAA'),\n",
    "    ]),\n",
    "]))\n",
    "#print(np.transpose(seqtools.seqs_to_onehots('GAAAACAAAAAAAAAAAAAA'), [1, 0, 2]).shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.0460593 , 0.02812302, 0.02792858, 0.05731571, 0.03083841,\n",
       "       0.02804673, 0.03832094, 0.04700711, 0.02779615, 0.0283931 ,\n",
       "       0.04557332, 0.0332604 , 0.03016231, 0.05645469, 0.03302583,\n",
       "       0.0484863 , 0.02797938, 0.05400315, 0.02882586, 0.03496324,\n",
       "       0.04873855, 0.04492734, 0.04271714, 0.04292899, 0.0295831 ,\n",
       "       0.02814495, 0.02986963, 0.03983732, 0.02804759, 0.0296664 ,\n",
       "       0.04291183, 0.04913203, 0.0594243 , 0.03603164, 0.05822189,\n",
       "       0.02809034, 0.03955992, 0.03785758, 0.04759109, 0.02794483,\n",
       "       0.02903815, 0.02818676, 0.03485832, 0.05141601, 0.05777366,\n",
       "       0.03794867, 0.05279316, 0.03054041, 0.02891738, 0.04118821,\n",
       "       0.04120168, 0.02811972, 0.02828982, 0.02797928, 0.03543286,\n",
       "       0.02983895, 0.05016077, 0.0286609 , 0.05125837, 0.03111096,\n",
       "       0.02861081, 0.04331847, 0.03831703, 0.05131742, 0.02793324,\n",
       "       0.0281919 , 0.05273511, 0.02894383, 0.04839699, 0.04375416,\n",
       "       0.05929791, 0.02888922, 0.04748857, 0.03278374, 0.03267288,\n",
       "       0.05017774, 0.04080175, 0.05779795, 0.03036874, 0.05946848,\n",
       "       0.04613841, 0.02806953, 0.02792521, 0.0466011 , 0.03369752,\n",
       "       0.05947883, 0.04820094, 0.03774684, 0.05042012, 0.02807076,\n",
       "       0.02795125, 0.03046418, 0.02837328, 0.02833067, 0.05409259,\n",
       "       0.0284669 , 0.03591277, 0.05294298, 0.02568221, 0.04367042],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder_trainer.model.predict(batch[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
