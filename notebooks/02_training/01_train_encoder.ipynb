{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Matplotlib created a temporary config/cache directory at /tmp/matplotlib-wj1e61vo because the default path (/tf/.cache/matplotlib) is not a writable directory; it is highly recommended to set the MPLCONFIGDIR environment variable to a writable directory, in particular to speed up the import of Matplotlib and to better support multiprocessing.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n",
      "1 Physical GPUs, 1 Logical GPUs\n"
     ]
    }
   ],
   "source": [
    "%pylab notebook\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow_probability as tfp\n",
    "import tensorflow.keras as keras\n",
    "from tensorflow.keras import layers\n",
    "import tensorflow.keras.backend as K\n",
    "from copy import deepcopy\n",
    "import secrets\n",
    "import os\n",
    "\n",
    "import primo.models\n",
    "import primo.datasets\n",
    "import primo.tools.sequences as seqtools\n",
    "from primo.models.cas9_keras import log_multisite_predictor\n",
    "from primo.models.encoder import entropy_regularizer\n",
    "\n",
    "# Enable memory growth so that we only use as much GPU memory as needed.\n",
    "# By default, tensorflow will reserve nearly all of the GPU memory.\n",
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "  try:\n",
    "    # Currently, memory growth needs to be the same across GPUs\n",
    "    for gpu in gpus:\n",
    "      tf.config.experimental.set_memory_growth(gpu, True)\n",
    "    logical_gpus = tf.config.list_logical_devices('GPU')\n",
    "    print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPUs\")\n",
    "  except RuntimeError as e:\n",
    "    # Memory growth must be set before GPUs have been initialized\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "switching to train_8.h5 and train_7.h5\n"
     ]
    }
   ],
   "source": [
    "train_dataset = primo.datasets.OpenImagesTrain(\n",
    "    '/tf/open_images/train/', switch_every=5*10**4\n",
    ")\n",
    "validation_dataset = primo.datasets.OpenImagesVal('/tf/open_images/validation/')\n",
    "\n",
    "# To see how this value was derived, please consult the Materials and Methods subsection under \n",
    "# Feature Extraction section in Bee et. al. 2021. \n",
    "similarity_threshold = 75\n",
    "# Intuitively determined:\n",
    "batch_size = 20\n",
    "val_batch_size = 150\n",
    "\n",
    "def keras_batch_generator(dataset_batch_generator):\n",
    "    # Yield datasets\n",
    "    # Each sample is a triplet with known similar and dissimilar images, so the y_true\n",
    "    # value is unused in the loss function.\n",
    "    while True:\n",
    "        # This tuple contains:\n",
    "        # indices: a positive integer uniquely identifying an image. This index is obtained by\n",
    "        #   enumerating all the images in the dataset (before splitting them into \n",
    "        #   test/train/validate datasets)\n",
    "        # triplets: A set of three image feature vectos containing anchor, positive (similar) \n",
    "        #   image, and negative (dissimilar) image\n",
    "        indices, triplets = next(dataset_batch_generator)\n",
    "        yield triplets, np.zeros(len(triplets))\n",
    "\n",
    "train_batch_generator = keras_batch_generator(\n",
    "    primo.datasets.dataset.triplet_batch_generator(\n",
    "        train_dataset.random_features(batch_size),\n",
    "        similarity_threshold\n",
    "    )\n",
    ")\n",
    "\n",
    "val_batch_generator = keras_batch_generator(\n",
    "    primo.datasets.dataset.triplet_batch_generator(\n",
    "        validation_dataset.random_features(val_batch_size),\n",
    "        similarity_threshold\n",
    "    )\n",
    ")\n",
    "\n",
    "train_inputs, train_targets = next(train_batch_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The reason the default encoder input is a 4096-dimensional vector is\n",
    "# because we're representing our images through an embedding that was learned\n",
    "# by a computer vision model known as VGG [1]. We're borrowing the output of the\n",
    "# 2nd fully-connected layer (i.e. the FC2), which spits out a 4096-by-1 vector.\n",
    "#\n",
    "# If you're very curious about VGG's innerworkings, you can see an example tensorflow\n",
    "# implementation here [2, 3].\n",
    "#\n",
    "# Note for future users: If you ever decide to use a different model VGG16,\n",
    "# you'd probably want to change the input dimension here.\n",
    "#\n",
    "# [1] - https://neurohive.io/en/popular-networks/vgg16/\n",
    "# [2] - https://www.cs.toronto.edu/~frossard/post/vgg16/\n",
    "# [3] - https://github.com/kentsommer/VGG16-Image-Retrieval/blob/master/vgg16_example.py#L237\n",
    "INPUT_FEATURE_SIZE = 4096 \n",
    "\n",
    "# Each CAS site is 20nt, so the output length should be 20nt for single\n",
    "# site, and a multiple of 20nt for multiple sites.\n",
    "OUTPUT_LEN = 20\n",
    "\n",
    "# Temperature used for softmax calculation\n",
    "SOFTMAX_TEMP = 1.0\n",
    "\n",
    "# Optionally, load a previously saved model to continue training\n",
    "MODEL_FILE=None\n",
    "\n",
    "def hardmax(temperature):\n",
    "    def hardmax_f(x):\n",
    "        y = tf.nn.softmax(x / temperature)\n",
    "        y_hard = tf.one_hot(tf.argmax(y, -1), 4)\n",
    "        y = tf.stop_gradient(y_hard - y) + y\n",
    "        return y\n",
    "    return hardmax_f\n",
    "\n",
    "# Create the keras model for a single encoder. This is instantiated three times in the\n",
    "# model, but trained together -- they will all share a set of weights.\n",
    "encoder = tf.keras.Sequential([\n",
    "    layers.Dense(4096, activation = 'relu', activity_regularizer=tf.keras.regularizers.l2(0.0000)),\n",
    "    layers.Dropout(0.2),\n",
    "    layers.Dense(4096, activation = 'relu', activity_regularizer=tf.keras.regularizers.l2(0.0000)),\n",
    "    layers.Dropout(0.2),\n",
    "    layers.Dense(OUTPUT_LEN * 4, activation='relu'),\n",
    "    layers.Reshape([OUTPUT_LEN, 4]),\n",
    "    layers.Lambda(hardmax(SOFTMAX_TEMP)),\n",
    "], name='encoder')\n",
    "\n",
    "# Start with previously trained model if a filename is provided\n",
    "if MODEL_FILE is not None:\n",
    "    encoder = tf.keras.models.load_model(MODEL_FILE)\n",
    "\n",
    "# First input is anchor, second is a positive sample, third is a negative sample\n",
    "X_triplets = layers.Input([3, INPUT_FEATURE_SIZE])\n",
    "\n",
    "# Essentially, we started with a batch of feature-vector triplets...\n",
    "# ...And turned them into a triplet of feature-vector batches.\n",
    "X1, X2, X3 = layers.Lambda(lambda X: (X[:,0,:], X[:,1,:], X[:,2,:]))(X_triplets)\n",
    "\n",
    "# Layer to compute euclidean distances between the triplet pairs for convenience\n",
    "distances = layers.Lambda(lambda Xs:\n",
    "                          (\n",
    "                              tf.sqrt(tf.reduce_sum(tf.square(Xs[0]-Xs[1]), axis=1)),\n",
    "                              tf.sqrt(tf.reduce_sum(tf.square(Xs[0]-Xs[2]), axis=1))\n",
    "                          ))([X1,X2,X3])\n",
    "\n",
    "# Independently transforms the batches of feature vectors into one-hot encoded DNA sequences.\n",
    "S1 = encoder(X1)\n",
    "S2 = encoder(X2)\n",
    "S3 = encoder(X3)\n",
    "\n",
    "# Glue them back together! Back into a batch of feature vector triplets.\n",
    "S_triplets = layers.Lambda(\n",
    "    lambda Ss: tf.stack(Ss, axis=-1)\n",
    ")([S1,S2,S3])\n",
    "\n",
    "# Dimensions: (batch_size x 80 x 4 x 3 ) (i.e. batch size x DNA length x # of nucleotides x 3)\n",
    "# Swaps dimensions for the loss function, which wants (batch-size x 3 x DNA length x 4)\n",
    "S_triplets_T = layers.Lambda(lambda S: tf.transpose(S, [0, 3, 1, 2]))(S_triplets)\n",
    "\n",
    "encoder_trainer = tf.keras.Model(inputs=X_triplets, outputs=S_triplets_T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defined the loss function, and metrics used for training\n",
    "\n",
    "def UniquenessMetric(y_true, y_pred):\n",
    "    seqs = encoder_trainer(train_inputs)\n",
    "    # Reduce seqs to a single base (e.g. [0.3, 0.1, 0.5, 0.1] -> [2])\n",
    "    rounded_seqs = K.argmax(seqs[:, 0, :, :], axis=-1)\n",
    "    unique_seqs = np.unique(K.get_value(rounded_seqs), axis=0)\n",
    "    # Return ratio of unique to input\n",
    "    return float(len(unique_seqs)) / len(train_inputs)\n",
    "\n",
    "def RecallMetric(y_true, y_pred):\n",
    "    Yp = log_multisite_predictor(tf.gather(y_pred, [0, 1], axis=1))\n",
    "    return tf.reduce_mean(tf.cast(Yp > -2.0, tf.float32))\n",
    "\n",
    "def NegRecallMetric(y_true, y_pred):\n",
    "    Yn = log_multisite_predictor(tf.gather(y_pred, [0, 2], axis=1))\n",
    "    return tf.reduce_mean(tf.cast(Yn > -2.0, tf.float32))\n",
    "            \n",
    "class EarlyStopCallback(keras.callbacks.Callback):\n",
    "    def __init__(self, **kwargs):\n",
    "        uid = secrets.token_hex(2)\n",
    "        self.__file = f'/tf/primo/signals/{uid}'\n",
    "        print(f\"Touch {self.__file} to terminate training early\")\n",
    "        super().__init__(**kwargs)\n",
    "\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        if os.path.exists(self.__file):\n",
    "          print (f\"\\nStopping after Epoch {epoch}\")\n",
    "          self.model.stop_training = True\n",
    "\n",
    "class TripletLoss(object):\n",
    "    def __init__(self, margin):\n",
    "        self.margin = margin\n",
    "    \n",
    "    def __call__(self, y_true, y_pred):\n",
    "        \"\"\"\n",
    "        y_pred is triplets of (anchor, positive, negative), with dimensions\n",
    "        batch_size x 3 x 20 x 4\n",
    "        \"\"\"\n",
    "        pos_distance = -log_multisite_predictor(tf.gather(y_pred, [0,1], axis=1))\n",
    "        neg_distance = log_multisite_predictor(tf.gather(y_pred, [0,2], axis=1))\n",
    "\n",
    "        # Compute loss function which penalizes low activation rate for positive \n",
    "        # pairs, and high activation rate for negative pairs, ignoring samples which\n",
    "        # are above (positive) or below (negative) thresholds -- i.e. samples which \n",
    "        # are already well trained are ignored.\n",
    "        return tf.maximum(pos_distance, 0.5) + tf.maximum(neg_distance, -3.0)\n",
    "       \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Touch /tf/primo/signals/f712 to terminate training early\n",
      "Epoch 1/2000\n",
      "  1/100 [..............................] - ETA: 1:44 - loss: 9.6729 - UniquenessMetric: 1.0000 - RecallMetric: 0.0000e+00 - NegRecallMetric: 0.0000e+00WARNING:tensorflow:5 out of the last 5 calls to <function dotproduct_crispr_spec at 0x7f43b3c78ea0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:6 out of the last 6 calls to <function dotproduct_crispr_spec at 0x7f43b3c78ea0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "100/100 [==============================] - 66s 655ms/step - loss: 3.6756 - UniquenessMetric: 0.8540 - RecallMetric: 0.1160 - NegRecallMetric: 0.0895 - val_loss: -0.0789 - val_UniquenessMetric: 0.6000 - val_RecallMetric: 0.9093 - val_NegRecallMetric: 0.8213\n",
      "Epoch 2/2000\n",
      "100/100 [==============================] - 65s 650ms/step - loss: 0.2574 - UniquenessMetric: 0.5665 - RecallMetric: 0.5745 - NegRecallMetric: 0.5185 - val_loss: 0.1767 - val_UniquenessMetric: 0.6000 - val_RecallMetric: 0.9627 - val_NegRecallMetric: 0.9440\n",
      "Epoch 3/2000\n",
      "100/100 [==============================] - 65s 655ms/step - loss: 0.1002 - UniquenessMetric: 0.5770 - RecallMetric: 0.7325 - NegRecallMetric: 0.6695 - val_loss: 0.1257 - val_UniquenessMetric: 0.5500 - val_RecallMetric: 0.9667 - val_NegRecallMetric: 0.9440\n",
      "Epoch 4/2000\n",
      "100/100 [==============================] - 66s 656ms/step - loss: 0.0285 - UniquenessMetric: 0.6150 - RecallMetric: 0.7210 - NegRecallMetric: 0.6555 - val_loss: -0.0635 - val_UniquenessMetric: 0.6500 - val_RecallMetric: 0.9560 - val_NegRecallMetric: 0.8893\n",
      "Epoch 5/2000\n",
      " 65/100 [==================>...........] - ETA: 22s - loss: 0.0585 - UniquenessMetric: 0.6854 - RecallMetric: 0.6808 - NegRecallMetric: 0.6362"
     ]
    }
   ],
   "source": [
    "### \n",
    "# Train with full dataset\n",
    "####\n",
    "encoder_trainer.compile(\n",
    "    tf.keras.optimizers.Adagrad(1e-4),\n",
    "    TripletLoss(0.9),\n",
    "    run_eagerly=True,\n",
    "    metrics=[UniquenessMetric, RecallMetric, NegRecallMetric,])\n",
    "history = encoder_trainer.fit(\n",
    "    train_batch_generator,\n",
    "    validation_data=val_batch_generator,\n",
    "    validation_steps=5,\n",
    "    steps_per_epoch=100,\n",
    "    epochs=2000,\n",
    "    callbacks=[EarlyStopCallback()],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "encoder.save('/tf/primo/data/models/encoder_multisite_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Plot training history\n",
    "fig = plt.figure()\n",
    "lines = [k for k in history.history.keys() if not k.startswith('val_')]\n",
    "axes = fig.subplots(int(len(lines)/2), 2)\n",
    "for i in range(len(lines)):\n",
    "    label = lines[i]\n",
    "    ax = axes.flatten()[i]\n",
    "    val_label = 'val_' + label\n",
    "    ax.plot(history.history[label], label=label)\n",
    "    if val_label in history.history:\n",
    "        ax.plot(history.history[val_label], linestyle=':', label=val_label)\n",
    "        ax.grid()\n",
    "    ax.legend()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
